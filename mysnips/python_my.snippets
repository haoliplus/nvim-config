priority 50

# vim:ft=snippets:
##########
# COMMON #
##########

# The smart def and smart class snippets use a global option called
# "g:ultisnips_python_style" which, if set to "doxygen" will use doxygen
# style comments in docstrings.

###########################################################################
#                            TEXTMATE SNIPPETS                            #
###########################################################################

snippet loggerinit "" b
from loguru import logger


def init_logger(base_name="temp.txt", log_dir=Path.home() / ".cache" / "log"):
	if len(base_name) == 0:
		base_name = "temp.txt"
	if Path(base_name).suffix != ".txt":
		base_name = f"{Path(base_name).stem}.txt"

	base_path = base_name
	if base_name[0] != "/":
		base_path = log_dir / base_name

	Path(base_path).parent.mkdir(parents=True, exist_ok=True)
	log_file_path = base_path
	cnt = 0
	while Path(log_file_path).exists():
		cnt += 1
		log_file_path = f"{Path(base_path).parent / Path(base_path).stem}.{cnt:06}.txt"

	logger.remove()
	logger.add(
		sys.stdout,
		colorize=True,
		format="<green>[{level:.1} {time:MM-DD HH:mm:ss.sss} {file}:{line}]</green> <level>{message}</level>",
	)
	logger.add(
		log_file_path,
		colorize=False,
		format="[{level} {process.name}.{thread.name} {time:MM-DD HH:mm:ss.sss} {file}:{line}] <level>{message}</level>",
	)
endsnippet


snippet loggerinit1 "init basic stdout logger" b
import sys
import logging

def init_logger(
):
	stream_handler = logging.StreamHandler(sys.stdout)
	stream_handler.setLevel(logging.INFO)
	logger = logging.getLogger()
	logger.handlers.clear()

	logging.basicConfig(
		level=logging.DEBUG,
		datefmt="%m-%d %H:%M:%S",
		format="[%(threadName)s %(asctime)s.%(msecs)03d %(filename)s:%(lineno)d] [%(levelname)s] %(message)s",
		handlers=[stream_handler],
	)
	return logging
endsnippet

snippet loggerinit2 "init logger with color" b
import sys
import logging
from pathlib import Path

class CustomFormatter(logging.Formatter):
	grey = "\x1b[38;20m"
	green = "\x1b[32;20m"
	yellow = "\x1b[33;20m"
	red = "\x1b[31;20m"
	bold_red = "\x1b[31;1m"
	reset = "\x1b[0m"
	# format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s (%(filename)s:%(lineno)d)"
	fmt = "[%(threadName)s %(asctime)s.%(msecs)03d %(filename)s:%(lineno)d] [%(levelname)s] %(message)s"

	FORMATS = {
		logging.DEBUG: grey + fmt + reset,
		logging.INFO: green + fmt + reset,
		logging.WARNING: yellow + fmt + reset,
		logging.ERROR: red + fmt + reset,
		logging.CRITICAL: bold_red + fmt + reset
	}

	def format(self, record):
		log_fmt = self.FORMATS.get(record.levelno)
		formatter = logging.Formatter(log_fmt)
		return formatter.format(record)

def init_logger(
	base_name="temp.log", log_dir=Path.home() / ".cache" / "log", reset=True
):
	if len(base_name) == 0:
		base_name = "temp.log"
	if Path(base_name).suffix != ".log":
		base_name = f"{Path(base_name).stem}.log"

	base_path = base_name
	if base_name[0] != "/":
		base_path = log_dir / base_name

	Path(base_path).parent.mkdir(parents=True, exist_ok=True)
	log_file_path = base_path
	cnt = 0
	while Path(log_file_path).exists():
		cnt += 1
		log_file_path = f"{base_path}.{cnt}"

	stream_handler = logging.StreamHandler(sys.stdout)
	stream_handler.setLevel(logging.INFO)
	stream_handler.setFormatter(CustomFormatter())
	file_handler = logging.FileHandler(log_file_path)
	file_handler.setLevel(logging.DEBUG)
	logger = logging.getLogger()
	if reset:
		logger.handlers.clear()

	logging.basicConfig(
		level=logging.DEBUG,
		datefmt="%m-%d %H:%M:%S",
		format="[%(threadName)s %(asctime)s.%(msecs)03d %(filename)s:%(lineno)d] [%(levelname)s] %(message)s",
		handlers=[stream_handler, logging.FileHandler(log_file_path)],
	)
	logger.info(f"Logging into {log_file_path}")
	logger.debug(f"Logging debug {log_file_path}")
	return logging
endsnippet

snippet loggerinit3 "full logger with argument color" b
import os
import logging
import colored
import sys
from pathlib import Path


class CustomFormatter(logging.Formatter):
	grey = "\x1b[38;20m"
	green = "\x1b[32;20m"
	yellow = "\x1b[33;20m"
	red = "\x1b[31;20m"
	bold_red = "\x1b[31;1m"
	reset = "\x1b[0m"
	# format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s (%(filename)s:%(lineno)d)"
	fmt = "[%(threadName)s %(asctime)s.%(msecs)03d %(filename)s:%(lineno)d:%(funcName)s()] [%(levelname)s] %(message)s"

	FORMATS = {
		logging.DEBUG: grey + fmt + reset,
		logging.INFO: green + fmt + reset,
		logging.WARNING: yellow + fmt + reset,
		logging.ERROR: red + fmt + reset,
		logging.CRITICAL: bold_red + fmt + reset,
	}

	def format(self, record):
		print(dir(record))

		msg = record.msg
		fg_col = (
			"" if not hasattr(record, "fg") else colored.fg(getattr(record, "fg"))
		)
		bg_col = (
			"" if not hasattr(record, "bg") else colored.bg(getattr(record, "bg"))
		)
		attr = (
			""
			if not hasattr(record, "attr")
			else colored.attr(getattr(record, "attr"))
		)
		msg = "%s%s%s%s%s" % (
			fg_col,
			bg_col,
			attr,
			msg,
			colored.attr("reset"),
		)
		record.msg = msg
		log_fmt = self.FORMATS.get(record.levelno)
		formatter = logging.Formatter(log_fmt)
		return formatter.format(record)


def init_logger(
	base_name="temp.log", log_dir=Path.home() / ".cache" / "log", reset=True
):
	if len(base_name) == 0:
		base_name = "temp.log"
	if Path(base_name).suffix != ".log":
		base_name = f"{Path(base_name).stem}.log"

	base_path = base_name
	if base_name[0] != "/":
		base_path = log_dir / base_name

	Path(base_path).parent.mkdir(parents=True, exist_ok=True)
	log_file_path = base_path
	cnt = 0
	while Path(log_file_path).exists():
		cnt += 1
		log_file_path = f"{base_path}.{cnt}"

	stream_handler = logging.StreamHandler(sys.stdout)
	stream_handler.setLevel(logging.INFO)
	stream_handler.setFormatter(CustomFormatter())
	file_handler = logging.FileHandler(log_file_path)
	file_handler.setLevel(logging.DEBUG)
	logger = logging.getLogger()
	if reset:
		logger.handlers.clear()

	logging.basicConfig(
		level=logging.DEBUG,
		datefmt="%m-%d %H:%M:%S",
		format="[%(threadName)s %(asctime)s.%(msecs)03d %(filename)s:%(lineno)d] [%(levelname)s] %(message)s",
		handlers=[stream_handler, logging.FileHandler(log_file_path)],
	)
	logger.info(f"Logging into {log_file_path}")
	logger.debug(f"Logging debug {log_file_path}")
	return logging
endsnippet

snippet ldproto "load proto" b
from google.protobuf import text_format
text_format.Parse(open(path, "r").read(), obj)
endsnippet

snippet ts2dt "float timestamp(second) to datetime" b
from datetime import datetime
dt_object = datetime.fromtimestamp(${1})
endsnippet

snippet dt2ts "datetime to float timestamp(second)" b
from datetime import datetime
dt = datetime(year=${1}, month=${2}, day=${3})
ts = datetime.timestamp(dt)
endsnippet

snippet strptime "parse datetime" b
from datetime import datetime
datetime.strptime("2021-01-02 10:00:00.123", "%Y-%m-%d %H:%M:%S.%f")
endsnippet

snippet strftime "format datetime" b
from datetime import datetime
now = datetime.now()
now.strftime("%Y-%m-%d %H:%M:%S.%f")
endsnippet

snippet jsonencoder "some to json" b
import json
import numpy as np
import datetime
from bson import ObjectId
class CustomEncoder(json.JSONEncoder):
	# json.dumps(data, cls=CustomEncoder)
	def default(self, obj):
		if isinstance(obj, np.integer):
			return int(obj)
		if isinstance(obj, np.floating):
			# alternatively use str()
			return float(obj)
		if isinstance(obj, np.ndarray):
			return obj.tolist()
		if isinstance(obj, (datetime.date, datetime.datetime)):
			return str(obj)
		if isinstance(obj, ObjectId):
			return str(obj)
		return json.JSONEncoder.default(self, obj)

json.dumps(obj, indent=2, cls=CustomEncoder)
endsnippet

#! header
snippet ifx "if __main__" b
if __name__ == `!p snip.rv = get_quoting_style(snip)`__main__`!p snip.rv = get_quoting_style(snip)`:
	${1:${VISUAL:main()}}
endsnippet

snippet mpasync "async multi process" b
import multiprocessing as mp

def task(slice, shared_data):
	pass

n_worker = 8
pool = mp.Pool(n_worker)
result_list = []
inp_list = [1, 2, 3, 4]
num = len(inp_list)
shared_data = None
num_slice = num // n_worker
for i in range(n_worker):
	tmp = inp_list[num_slice * i : num_slice * (i + 1)]
	result_list.append(pool.apply_async(task, args=(tmp[:], shared_data)))
pool.close()
pool.join()

results = [result.get() for result in result_list]
endsnippet

snippet multithread "async multi thread" b
import threading
class MyThread(threading.Thread):
	def run(self):
		pass

for f in range(4):
	t = MyThread()
	t.start()
	t.join()
endsnippet

snippet argparse "arguments" b
import argparse
parser = argparse.ArgumentParser(description="config evaluate")
parser.add_argument(
	"--name",
	default=None,
	type=str,
)
args = parser.parse_args()
endsnippet
